@article{luhun1958,
  title={The Automatic Creation of Literature Abstracts},
  author={Luhn, H. P.},
  year={1958},
  journal={IBM Journal of Research and Development},
  url={https://psycnet.apa.org/doi/10.1147/rd.22.0159}
}

@inproceedings{mihalcea2004textrank,
  title={TextRank: Bringing Order into Texts},
  author={Mihalcea, R. and Tarau, P.},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2004},
  url={https://aclanthology.org/W04-3252.pdf}
}

@inproceedings{collins-etal-2017-supervised,
    title = "A Supervised Approach to Extractive Summarisation of Scientific Papers",
    author = "Collins, Ed  and
      Augenstein, Isabelle  and
      Riedel, Sebastian",
    editor = "Levy, Roger  and
      Specia, Lucia",
    booktitle = "Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/K17-1021",
    doi = "10.18653/v1/K17-1021",
    pages = "195--205",
    abstract = "Automatic summarisation is a popular approach to reduce a document to its main arguments. Recent research in the area has focused on neural approaches to summarisation, which can be very data-hungry. However, few large datasets exist and none for the traditionally popular domain of scientific publications, which opens up challenging research avenues centered on encoding large, complex documents. In this paper, we introduce a new dataset for summarisation of computer science publications by exploiting a large resource of author provided summaries and show straightforward ways of extending it further. We develop models on the dataset making use of both neural sentence encoding and traditionally used summarisation features and show that models which encode sentences as well as their local and global context perform best, significantly outperforming well-established baseline methods.",
}

@misc{acl,
  title = {ACL Anthology},
  url = {https://aclanthology.org/},
  note = {Accessed on December 4th 2023}
}

@misc{naacl,
  title = {NAACL: North American Chapter of the ACL (Association for Computational Linguistics)},
  url = {https://naacl.org/},
  note = {Accessed on December 4th 2023}
}

@misc{elicit,
  title = {Elicit},
  url = {https://elicit.com/},
  note = {Accessed on December 4th 2023}
}

@misc{scite,
  title = {Scite},
  url = {https://scite.ai/},
  note = {Accessed on December 4th 2023}
}

@article{knight2000statistics,
  title={Statistics-based summarization-step one: Sentence compression},
  author={Knight and Kevin and Marcu, Daniel},
  journal={AAAI/IAAI},
  volume={2000},
  pages={703--710},
  year={2000}
}

@article{liu2018,
  author    = {Peter J. Liu and
               Mohammad Saleh and
               Etienne Pot and
               Ben Goodrich and
               Ryan Sepassi and
               Lukasz Kaiser and
               Noam Shazeer},
  title     = {Generating Wikipedia by Summarizing Long Sequences},
  journal = {International Conference on Learning Representations},
  year      = {2018}
},

@article{fabbri2019multi-news,
  author    = {Alexander Fabbri and
               Irene Li and
               Tianwei She and
               Suyi Li and
               Dragomir Radev},
  title     = {Multi-news: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model},
  journal = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages     = {1074--1084},
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics}
},

@misc{arxivstats,
  title   = {arXiv Statistics},
  url     = {https://info.arxiv.org/help/stats/2021_by_area/index.html},
  note    = {Accessed on September 22, 2023}
},

@inproceedings{lu2020multixscience,
  author    = {Yao Lu and
               Yue Dong and
               Laurent Charlin},
  title     = {MultiXScience: A Large-Scale Dataset for Extreme Multidocument Summarization of Scientific Articles},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages     = {8068--8074},
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics}
}

@article{fewshot,
  author       = {Tom B. Brown and
                  Benjamin Mann and
                  Nick Ryder and
                  Melanie Subbiah and
                  Jared Kaplan and
                  Prafulla Dhariwal and
                  Arvind Neelakantan and
                  Pranav Shyam and
                  Girish Sastry and
                  Amanda Askell and
                  Sandhini Agarwal and
                  Ariel Herbert{-}Voss and
                  Gretchen Krueger and
                  Tom Henighan and
                  Rewon Child and
                  Aditya Ramesh and
                  Daniel M. Ziegler and
                  Jeffrey Wu and
                  Clemens Winter and
                  Christopher Hesse and
                  Mark Chen and
                  Eric Sigler and
                  Mateusz Litwin and
                  Scott Gray and
                  Benjamin Chess and
                  Jack Clark and
                  Christopher Berner and
                  Sam McCandlish and
                  Alec Radford and
                  Ilya Sutskever and
                  Dario Amodei},
  title        = {Language Models are Few-Shot Learners},
  journal      = {CoRR},
  volume       = {abs/2005.14165},
  year         = {2020},
  url          = {https://arxiv.org/abs/2005.14165},
  eprinttype    = {arXiv},
  eprint       = {2005.14165},
  timestamp    = {Thu, 25 May 2023 10:38:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{RoBERTa,
  author       = {Yinhan Liu and
                  Myle Ott and
                  Naman Goyal and
                  Jingfei Du and
                  Mandar Joshi and
                  Danqi Chen and
                  Omer Levy and
                  Mike Lewis and
                  Luke Zettlemoyer and
                  Veselin Stoyanov},
  title        = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal      = {CoRR},
  volume       = {abs/1907.11692},
  year         = {2019},
  url          = {http://arxiv.org/abs/1907.11692},
  eprinttype    = {arXiv},
  eprint       = {1907.11692},
  timestamp    = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Radford2018ImprovingLU,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Alec Radford and Karthik Narasimhan},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:49313245}
}

@article{LexRank,
  author       = {G{\"{u}}nes Erkan and
                  Dragomir R. Radev},
  title        = {LexRank: Graph-based Lexical Centrality as Salience in Text Summarization},
  journal      = {CoRR},
  volume       = {abs/1109.2128},
  year         = {2011},
  url          = {http://arxiv.org/abs/1109.2128},
  eprinttype    = {arXiv},
  eprint       = {1109.2128},
  timestamp    = {Mon, 13 Aug 2018 16:48:09 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1109-2128.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{SeeLM17,
  author       = {Abigail See and
                  Peter J. Liu and
                  Christopher D. Manning},
  title        = {Get To The Point: Summarization with Pointer-Generator Networks},
  journal      = {CoRR},
  volume       = {abs/1704.04368},
  year         = {2017},
  url          = {http://arxiv.org/abs/1704.04368},
  eprinttype    = {arXiv},
  eprint       = {1704.04368},
  timestamp    = {Mon, 13 Aug 2018 16:46:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/SeeLM17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{rush2015neural,
  author       = {Alexander M. Rush and
                  Sumit Chopra and
                  Jason Weston},
  title        = {A Neural Attention Model for Abstractive Sentence Summarization},
  journal      = {CoRR},
  volume       = {abs/1509.00685},
  year         = {2015},
  url          = {http://arxiv.org/abs/1509.00685},
  eprinttype    = {arXiv},
  eprint       = {1509.00685},
  timestamp    = {Mon, 13 Aug 2018 16:46:49 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/RushCW15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{PaulusXS17,
  author       = {Romain Paulus and
                  Caiming Xiong and
                  Richard Socher},
  title        = {A Deep Reinforced Model for Abstractive Summarization},
  journal      = {CoRR},
  volume       = {abs/1705.04304},
  year         = {2017},
  url          = {http://arxiv.org/abs/1705.04304},
  eprinttype    = {arXiv},
  eprint       = {1705.04304},
  timestamp    = {Mon, 13 Aug 2018 16:48:58 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/PaulusXS17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}