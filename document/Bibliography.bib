@article{luhn1958,
  title={The Automatic Creation of Literature Abstracts},
  author={Luhn, H. P.},
  year={1958},
  url={https://psycnet.apa.org/doi/10.1147/rd.22.0159}
}

@inproceedings{mihalcea2004textrank,
  title={TextRank: Bringing Order into Texts},
  author={Mihalcea, R. and Tarau, P.},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2004},
  url={https://aclanthology.org/W04-3252.pdf}
}

@inproceedings{collins-etal-2017-supervised,
    title = "A Supervised Approach to Extractive Summarisation of Scientific Papers",
    author = "Collins, Ed  and
      Augenstein, Isabelle  and
      Riedel, Sebastian",
    editor = "Levy, Roger  and
      Specia, Lucia",
    booktitle = "Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/K17-1021",
    doi = "10.18653/v1/K17-1021",
    pages = "195--205",
    abstract = "Automatic summarisation is a popular approach to reduce a document to its main arguments. Recent research in the area has focused on neural approaches to summarisation, which can be very data-hungry. However, few large datasets exist and none for the traditionally popular domain of scientific publications, which opens up challenging research avenues centered on encoding large, complex documents. In this paper, we introduce a new dataset for summarisation of computer science publications by exploiting a large resource of author provided summaries and show straightforward ways of extending it further. We develop models on the dataset making use of both neural sentence encoding and traditionally used summarisation features and show that models which encode sentences as well as their local and global context perform best, significantly outperforming well-established baseline methods.",
}

@online{acl,
  title = {ACL Anthology},
  url = {https://aclanthology.org/},
  note = {Accessed on December 4th 2023}
}

@online{naacl,
  title = {NAACL: North American Chapter of the ACL (Association for Computational Linguistics)},
  url = {https://naacl.org/},
  note = {Accessed on December 4th 2023}
}

@online{elicit
  title = {Elicit},
  url = {https://elicit.com/},
  note = {Accessed on December 4th 2023}
}

@online{scite
  title = {Scite}
  url = {https://scite.ai/},
  note = {Accessed on December 4th 2023}
}

@article{knight2000statistics,
  title={Statistics-based summarization-step one: Sentence compression},
  author={Knight, Kevin and Marcu, Daniel},
  journal={AAAI/IAAI},
  volume={2000},
  pages={703--710},
  year={2000}
}

@article{liu2018,
  author    = {Peter J. Liu and
               Mohammad Saleh and
               Etienne Pot and
               Ben Goodrich and
               Ryan Sepassi and
               Lukasz Kaiser and
               Noam Shazeer},
  title     = {Generating Wikipedia by Summarizing Long Sequences},
  journal = {International Conference on Learning Representations},
  year      = {2018}
},

@article{fabbri2019multi-news,
  author    = {Alexander Fabbri and
               Irene Li and
               Tianwei She and
               Suyi Li and
               Dragomir Radev},
  title     = {Multi-news: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model},
  journal = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages     = {1074--1084},
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics}
},

@online{arxivstats,
  title   = {arXiv Statistics},
  url     = {https://info.arxiv.org/help/stats/2021_by_area/index.html},
  note    = {Accessed on September 22, 2023}
},

@inproceedings{lu2020multixscience,
  author    = {Yao Lu and
               Yue Dong and
               Laurent Charlin},
  title     = {MultiXScience: A Large-Scale Dataset for Extreme Multidocument Summarization of Scientific Articles},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages     = {8068--8074},
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics}
}
